{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Environment Set up**"
      ],
      "metadata": {
        "id": "d1apB9ldjgR3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usirN4OM8KbH",
        "outputId": "a27e2c5d-4dae-48e7-c755-ba56f817cc79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install -q --upgrade google-generativeai langchain-google-genai langchain langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import textwrap\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "TMibFVcQ9KB7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text,'>',predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "Fo1JPU0oAFBI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('Pro_1')\n",
        "genai. configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "1VO9jR-N9byl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calling a Prompt using LLM API**"
      ],
      "metadata": {
        "id": "Si6rl0qgjpoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-pro\")\n",
        "\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi5dQ945-qSh",
        "outputId": "6858b06c-29cf-4818-b709-98039fe4b9d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-pro',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What is Langchain\")"
      ],
      "metadata": {
        "id": "w38kZbPj_VH1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzUCHoriBErZ",
        "outputId": "585fa0cc-7505-4ca7-ff9c-c2a8c672494a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "response:\n",
              "GenerateContentResponse(\n",
              "    done=True,\n",
              "    iterator=None,\n",
              "    result=glm.GenerateContentResponse({\n",
              "      \"candidates\": [\n",
              "        {\n",
              "          \"content\": {\n",
              "            \"parts\": [\n",
              "              {\n",
              "                \"text\": \"Langchain is a decentralized AI/ML collaborative platform that empowers data scientists to build, train, and deploy machine learning models in a secure and transparent environment.\\n\\n**Key Features:**\\n* **Decentralized Data Storage:** Langchain uses a decentralized network of nodes to store and process data, ensuring privacy and preventing data manipulation.\\n* **Collaborative Model Development:** Data scientists can collaborate on model building, allowing for knowledge sharing and collective problem-solving.\\n* **Transparency:** All model development processes are recorded on the Langchain blockchain, providing a verifiable history of each model.\\n* **Model Marketplace:** A marketplace for ML models allows users to discover, buy, and sell pre-trained models.\\n* **Machine Learning Compute Pool:** A distributed compute pool provides affordable and scalable resources for training ML models.\\n* **Model Monitoring:** Langchain monitors model performance in real-time, identifying any issues or drift that may occur.\\n\\n**Benefits:**\\n\\n* **Enhanced Privacy:** Decentralized storage protects data from unauthorized access and manipulation.\\n* **Increased Collaboration:** Facilitates collaboration between data scientists, leading to improved model quality.\\n* **Transparency and Trust:** Blockchain technology ensures a transparent and verifiable model development process.\\n* **Reduced Costs:** Distributed compute resources offer cost-effective model training solutions.\\n* **Access to Pre-Trained Models:** The marketplace provides access to a vast collection of ML models, saving time and resources.\\n\\nLangchain aims to revolutionize the field of machine learning by providing a decentralized and secure platform for collaboration, transparency, and innovation.\"\n",
              "              }\n",
              "            ],\n",
              "            \"role\": \"model\"\n",
              "          },\n",
              "          \"finish_reason\": 1,\n",
              "          \"index\": 0,\n",
              "          \"safety_ratings\": [\n",
              "            {\n",
              "              \"category\": 9,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            },\n",
              "            {\n",
              "              \"category\": 8,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            },\n",
              "            {\n",
              "              \"category\": 7,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            },\n",
              "            {\n",
              "              \"category\": 10,\n",
              "              \"probability\": 1,\n",
              "              \"blocked\": false\n",
              "            }\n",
              "          ],\n",
              "          \"token_count\": 0,\n",
              "          \"grounding_attributions\": []\n",
              "        }\n",
              "      ],\n",
              "      \"usage_metadata\": {\n",
              "        \"prompt_token_count\": 4,\n",
              "        \"candidates_token_count\": 317,\n",
              "        \"total_token_count\": 321\n",
              "      }\n",
              "    }),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "lSUDqPTa_wRQ",
        "outputId": "33466921-1991-4cb3-e311-4f7494dcb631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Langchain is a decentralized AI/ML collaborative platform that empowers data scientists to build, train, and deploy machine learning models in a secure and transparent environment.\n>\n>**Key Features:**\n>* **Decentralized Data Storage:** Langchain uses a decentralized network of nodes to store and process data, ensuring privacy and preventing data manipulation.\n>* **Collaborative Model Development:** Data scientists can collaborate on model building, allowing for knowledge sharing and collective problem-solving.\n>* **Transparency:** All model development processes are recorded on the Langchain blockchain, providing a verifiable history of each model.\n>* **Model Marketplace:** A marketplace for ML models allows users to discover, buy, and sell pre-trained models.\n>* **Machine Learning Compute Pool:** A distributed compute pool provides affordable and scalable resources for training ML models.\n>* **Model Monitoring:** Langchain monitors model performance in real-time, identifying any issues or drift that may occur.\n>\n>**Benefits:**\n>\n>* **Enhanced Privacy:** Decentralized storage protects data from unauthorized access and manipulation.\n>* **Increased Collaboration:** Facilitates collaboration between data scientists, leading to improved model quality.\n>* **Transparency and Trust:** Blockchain technology ensures a transparent and verifiable model development process.\n>* **Reduced Costs:** Distributed compute resources offer cost-effective model training solutions.\n>* **Access to Pre-Trained Models:** The marketplace provides access to a vast collection of ML models, saving time and resources.\n>\n>Langchain aims to revolutionize the field of machine learning by providing a decentralized and secure platform for collaboration, transparency, and innovation."
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calling a Prompt using Langchain**"
      ],
      "metadata": {
        "id": "rfmgi7MgkLAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "HfHMhFIOBnX2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key= GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "5JS3354RKQbj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(\"Give 5 use cases for langchain\")"
      ],
      "metadata": {
        "id": "CCtZMDDLKfhq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI_7Np4JKr5b",
        "outputId": "88370bc8-5ba1-43a9-864e-42557d7f07de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='**1. Cross-Chain Interoperability:**\\n* Enable seamless transfer of assets, data, and smart contract execution across different blockchain networks.\\n\\n**2. Token Bridge Security:**\\n* Securely connect blockchains and facilitate cross-chain token transfers with enhanced security measures.\\n\\n**3. Multi-Chain DApp Development:**\\n* Develop decentralized applications (DApps) that seamlessly interact with multiple blockchains, addressing interoperability challenges.\\n\\n**4. Cross-Chain Fraud Detection:**\\n* Monitor transactions across multiple chains to identify and mitigate fraudulent activities.\\n\\n**5. Blockchain Data Analytics:**\\n* Collect and analyze data from various blockchains to provide comprehensive insights for decision-making and risk assessment.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-e82d755e-6332-4d9d-b193-e790ac6fc2f8-0', usage_metadata={'input_tokens': 9, 'output_tokens': 142, 'total_tokens': 151})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "Jb0e06dqKvJd",
        "outputId": "355701cd-df34-4aa9-aaf3-4c7f24ead52c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">**1. Cross-Chain Interoperability:**\n>* Enable seamless transfer of assets, data, and smart contract execution across different blockchain networks.\n>\n>**2. Token Bridge Security:**\n>* Securely connect blockchains and facilitate cross-chain token transfers with enhanced security measures.\n>\n>**3. Multi-Chain DApp Development:**\n>* Develop decentralized applications (DApps) that seamlessly interact with multiple blockchains, addressing interoperability challenges.\n>\n>**4. Cross-Chain Fraud Detection:**\n>* Monitor transactions across multiple chains to identify and mitigate fraudulent activities.\n>\n>**5. Blockchain Data Analytics:**\n>* Collect and analyze data from various blockchains to provide comprehensive insights for decision-making and risk assessment."
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Templates**"
      ],
      "metadata": {
        "id": "2PhLvVJYTksr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_for_framework = PromptTemplate(\n",
        "    input_variables = ['framework'],\n",
        "    template = \"What is {framework}\"\n",
        ")"
      ],
      "metadata": {
        "id": "YlO6mOKxPnR3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_for_framework.format(framework = \"langchain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zd1dq6bzTHns",
        "outputId": "7f193479-1bbc-4087-e87e-ebe1fc79c4fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is langchain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template_for_framework.format(framework=\"Hugging Face Transformer\")\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UESGqbPo_VFK",
        "outputId": "85560ba4-e24e-4296-9eb5-4f8056af542c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is Hugging Face Transformer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.invoke(prompt)\n",
        "\n",
        "to_markdown(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "T7QOxtGylyVC",
        "outputId": "0e830813-92eb-4bf6-9f6b-a1391e87efa8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">**Hugging Face Transformer**\n>\n>Hugging Face Transformer is a natural language processing (NLP) library that provides state-of-the-art pretrained transformer models and tools for training, fine-tuning, and deploying NLP models.\n>\n>**Key Features:**\n>\n>* **Pretrained Transformers:** Includes a wide range of pretrained transformer models from various architectures (e.g., BERT, GPT, T5) and domains (e.g., language modeling, text classification).\n>* **Model Hub:** A central repository where users can share and access pretrained models, datasets, and pipelines.\n>* **Fine-tuning and Training:** Tools for fine-tuning and training custom NLP models using various datasets and training algorithms.\n>* **Pipelines:** Pre-built pipelines for common NLP tasks such as text classification, question answering, and text generation.\n>* **Integration with Hugging Face Hub:** Allows users to easily upload, share, and collaborate on models and datasets.\n>* **Support for Popular Frameworks:** Integrates with popular deep learning frameworks such as TensorFlow, PyTorch, and JAX.\n>\n>**Benefits:**\n>\n>* **Accelerated NLP Development:** Provides access to pretrained models, saving time and resources on model creation.\n>* **State-of-the-Art Performance:** Leverages the latest transformer architectures and training techniques for optimal performance.\n>* **Flexibility and Customization:** Allows fine-tuning and training of models to suit specific needs.\n>* **Community Support:** Backed by a large and active community that provides resources, tutorials, and support.\n>* **Easy Deployment:** Supports deployment of trained models for real-world applications.\n>\n>**Use Cases:**\n>\n>Hugging Face Transformer is widely used for various NLP tasks, including:\n>\n>* Text classification\n>* Question answering\n>* Text generation\n>* Sentiment analysis\n>* Machine translation\n>* Named entity recognition\n>* Summarization"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chains**"
      ],
      "metadata": {
        "id": "ryiRp9byTq1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "z6x-7JAPT055"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_template_for_vacation = PromptTemplate(\n",
        "    input_variables = ['continent'],\n",
        "    template = \"I'm planning a vaction.Suggest one country to visit in {continent}. Give only the country name\"\n",
        ")"
      ],
      "metadata": {
        "id": "iBG_lVw7y0v9"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain (llm = llm, prompt=prompt_template_for_vacation)\n",
        "\n",
        "output = chain.run(\"Europe\")\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WCXpTcLYUHv1",
        "outputId": "eddbfbcd-e6e5-4239-8be8-1264fd4018ed"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spain'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simple Sequential Chain**"
      ],
      "metadata": {
        "id": "tSInrRkvWirD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain"
      ],
      "metadata": {
        "id": "gSbiZ9Ql0-Ky"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_for_vacation = PromptTemplate(\n",
        "    input_variables = ['continent'],\n",
        "    template = \"I'm planning a vaction.Suggest one country to visit in {continent}\"\n",
        ")\n",
        "\n",
        "vacation_chain = LLMChain(llm=llm, prompt=prompt_template_for_vacation)\n",
        "\n",
        "prompt_template_activities = PromptTemplate(\n",
        "    input_variables=[\"country_name\"],\n",
        "    template=\"Suggest 10 activites to do while on vacation in {country_name}\"\n",
        ")\n",
        "\n",
        "vacation_activities_chain = LLMChain(llm=llm, prompt=prompt_template_activities)"
      ],
      "metadata": {
        "id": "2QovlQ2EWsLo"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SS_chain = SimpleSequentialChain(chains = [vacation_chain, vacation_activities_chain])\n",
        "\n",
        "output = SS_chain.run(\"Africa\")\n",
        "\n",
        "to_markdown(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "mbOKt90Cmv5x",
        "outputId": "a2b7031d-c003-42ef-c837-e26d76d850a1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">**10 Activities to Do While on Vacation in Kenya:**\n>\n>1. **Embark on a Wildlife Safari in Maasai Mara National Reserve:** Witness the \"Big Five\" (lions, elephants, leopards, rhinos, and buffaloes) in their natural habitat.\n>2. **Relax on Diani Beach:** Enjoy the sun-kissed shores and turquoise waters of this popular coastal destination.\n>3. **Visit the Nairobi National Museum:** Learn about Kenya's rich history, culture, and biodiversity.\n>4. **Hike Mount Kenya:** Ascend the scenic trails to the summit of Africa's second-highest mountain for panoramic views.\n>5. **Explore Fort Jesus in Mombasa:** Discover the historical significance of this UNESCO World Heritage Site, a testament to Kenya's coastal heritage.\n>6. **Experience Maasai Culture at a Traditional Village:** Immerse yourself in the vibrant traditions and customs of the Maasai people.\n>7. **Go White-Water Rafting on the Tana River:** Tackle the rapids and enjoy the breathtaking scenery on Kenya's longest river.\n>8. **Witness the Great Migration in Masai Mara:** Observe the awe-inspiring spectacle of millions of animals migrating across the savanna.\n>9. **Hot Air Balloon Ride over Maasai Mara:** Get a bird's-eye view of the wildlife-rich plains from the air.\n>10. **Visit Lake Naivasha:** Explore this picturesque freshwater lake, home to diverse birdlife and a variety of wildlife."
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sequential Chain**"
      ],
      "metadata": {
        "id": "02V2vPhyWtsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "\n",
        "prompt_template_for_vacation = PromptTemplate(\n",
        "    input_variables = ['continent'],\n",
        "    template = \"I'm planning a vaction.Suggest one country to visit in {continent}\"\n",
        ")\n",
        "\n",
        "vacation_chain = LLMChain(llm=llm, prompt=prompt_template_for_vacation, output_key=\"country\")\n",
        "\n",
        "\n",
        "prompt_template_activities = PromptTemplate(\n",
        "    input_variables=[\"country\"],\n",
        "    template=\"Suggest 10 activites to do while on vacation in {country}\"\n",
        ")\n",
        "\n",
        "vacation_activities_chain = LLMChain(llm=llm, prompt=prompt_template_activities, output_key=\"activities\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9MH1DvDIWhGU"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S_chain = SequentialChain(\n",
        "    chains = [vacation_chain, vacation_activities_chain],\n",
        "    input_variables = [\"continent\"],\n",
        "    output_variables = [\"country\", \"activities\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "4RxC6yTB5sPt"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = S_chain({'continent':\"Europe\"})\n",
        "\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMhd_iWT4bI8",
        "outputId": "913370f9-1bac-43f2-c4ab-a6131eec9974"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'continent': 'Europe',\n",
              " 'country': \"**Italy:**\\n\\n* **Rich history and culture:** Home to ancient ruins, iconic architecture, and masterpieces of art and literature.\\n* **Diverse landscapes:** From the rolling hills of Tuscany to the dramatic cliffs of the Amalfi Coast, Italy offers stunning scenery.\\n* **Delicious cuisine:** Known for its pizzas, pastas, and gelato, Italy is a foodie's paradise.\\n* **Vibrant cities:** Visit Rome, Florence, and Venice for a blend of history, art, and culture.\\n* **Easy to travel:** Italy has a well-developed transportation system, making it easy to explore.\",\n",
              " 'activities': \"1. **Visit the Colosseum and Roman Forum in Rome:** Step back in time at these iconic landmarks of the Roman Empire.\\n2. **Explore the Uffizi Gallery in Florence:** Admire masterpieces by Botticelli, Michelangelo, and Leonardo da Vinci.\\n3. **Stroll through the canals of Venice:** Take a gondola ride or walk along the picturesque bridges and streets.\\n4. **Hike the Cinque Terre:** Trek along the rugged coastline and visit the colorful villages perched on the cliffs.\\n5. **Sunbathe on the beaches of the Amalfi Coast:** Relax and soak up the stunning views of the sea and mountains.\\n6. **Visit the ruins of Pompeii:** Explore the preserved ancient city frozen in time by a volcanic eruption.\\n7. **Indulge in a cooking class:** Learn to prepare traditional Italian dishes and savor the local flavors.\\n8. **Attend a wine tasting in Tuscany:** Sample the region's renowned wines and visit picturesque vineyards.\\n9. **Explore the art and architecture of Milan:** Visit the Duomo Cathedral, La Scala Opera House, and Sforza Castle.\\n10. **Shop for souvenirs and local products:** Find unique gifts and treasures in the markets and boutiques of Italian cities and towns.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Agents**"
      ],
      "metadata": {
        "id": "w9uFg-vtYP7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent, load_tools, initialize_agent, AgentType"
      ],
      "metadata": {
        "id": "C50YZVyWYVcr"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  wikipedia arxiv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FF8mzAcCQEp",
        "outputId": "25ab45c5-1c8f-42b7-ec7a-6fbbac9f1718"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools([\"arxiv\", \"wikipedia\"], llm=llm)"
      ],
      "metadata": {
        "id": "W-AO4nDApHYY"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCC02wE5CD1t",
        "outputId": "f225501f-d209-4652-9a01-e9f6e902dedc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Who is the current leader of Afghanistan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "OwiL43HJCeRy",
        "outputId": "17faab85-7b67-46d9-8bfe-60bfd231dc06"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: Who is the current leader of Afghanistan\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mPage: Supreme Leader of Afghanistan\n",
            "Summary: The Supreme Leader of Afghanistan (Pashto: د افغانستان مشر, romanized: Də Afġānistān Damshīr, Dari: رهبر افغانستان, romanized: Rahbar-e Afghānistān), officially the Supreme Leader of the Islamic Emirate of Afghanistan and also styled by his religious title Amir al-Mu'minin (Arabic, lit. 'Commander of the Faithful'), is the absolute ruler, head of state, and national religious leader of Afghanistan, as well as the leader of the Taliban. The supreme leader wields unlimited authority and is the ultimate source of all law.\n",
            "The first supreme leader, Mullah Omar, ruled Afghanistan from 1996 to 2001 before his government was overthrown by the United States and he was forced into exile. The current supreme leader is Hibatullah Akhundzada, who assumed office in exile during the Taliban insurgency on 25 May 2016, upon being chosen by the Leadership Council, and came to power on 15 August 2021 with the Taliban's victory over U.S.-backed forces in the 2001–2021 war. Since coming to power, Akhundzada has issued numerous decrees that have profoundly reshaped government and daily life in Afghanistan by implementing his strict interpretation of the Hanafi school of Sharia law.\n",
            "The supreme leader appoints and manages the activities of the prime minister and other members of the Cabinet, as well as judges and provincial and local leaders.\n",
            "\n",
            "Page: Government of Afghanistan\n",
            "Summary: The government of Afghanistan, officially called the Islamic Emirate of Afghanistan, is the central government of Afghanistan, a unitary state. Under the leadership of the Taliban, the government is a theocracy and an emirate with political power concentrated in the hands of a supreme leader and his clerical advisors, collectively referred to as the Leadership. The Leadership makes all major policy decisions behind closed doors, which are then implemented by the country's civil service and judiciary. As Afghanistan is an Islamic state, governance is based on Sharia law and Pashtunwali, which the Taliban enforces strictly through extensive social and cultural policy.\n",
            "Over its history, Afghanistan has variously been governed as a monarchy, a republic, and a theocracy. The current theocratic government came to power in 2021 with the Taliban's victory in a twenty-year insurgency against the western-backed Islamic Republic, after having itself been ousted in 2001.\n",
            "The current government is internationally unrecognized and lacks a clear constitutional basis, though the Taliban announced plans in January 2022 to form a constitutional commission. Instead, the government applies an interpretation of Sharia law. There is no separation of powers, with total authority vested in the Leadership. The government is criticized by international observers for totalitarianism, systemic human rights violations, as well as for being unaccountable, opaque, and exclusive of women, religious and ethnic minorities, and those with dissenting views. Since coming to power, it has grappled with an economic crisis, international isolation, terrorism and rebellion, and a string of natural disasters.\n",
            "\n",
            "\n",
            "\n",
            "Page: List of current heads of state and government\n",
            "Summary: This is a list of current heads of state and heads of government. In some cases, mainly in presidential systems, one leader is head of state and head of government. In other cases, mainly in semi-presidential and parliamentary systems, the head of state and the head of government are different people. In semi-presidential and parliamentary systems, the head of government role (i.e. executive branch) is fulfilled by the listed head of government and the head of state.\n",
            "In one-party states, the ruling party's leader (i.e. General Secretary) is usually the de facto top leader of the state, though sometimes this leader also holds the presidency or premiership. In some countries like Andorra and Vatican City (Holy See), a clergy member also acts as the head of state for both countries (Bishop of Urgell a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Hibatullah Akhundzada\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hibatullah Akhundzada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Memory**"
      ],
      "metadata": {
        "id": "6lIxDdX6FD3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_for_vacation = PromptTemplate(\n",
        "    input_variables = ['continent'],\n",
        "    template = \"I'm planning a vaction.Suggest one country to visit in {continent}. Give only the country name\"\n",
        ")"
      ],
      "metadata": {
        "id": "eUJBxj34KlDb"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain (llm = llm, prompt=prompt_template_for_vacation)\n",
        "\n",
        "country = chain.run(\"America\")\n",
        "\n",
        "to_markdown(country)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "vzSlJhjJIn1h",
        "outputId": "025cd3ce-7ea8-4fa0-b7bc-0762f2178252"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Mexico"
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain (llm = llm, prompt=prompt_template_for_vacation)\n",
        "\n",
        "country = chain.run(\"Africa\")\n",
        "\n",
        "to_markdown(country)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "R6Bhcc9yKpzo",
        "outputId": "0783f7e6-6b51-4d20-e888-83db60906440"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Tanzania"
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gebZ6m83FkbF",
        "outputId": "c27927de-acdd-4a4e-b1d0-c0096df90fd5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conversation Buffer Memory**"
      ],
      "metadata": {
        "id": "B356vpkkGg6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n"
      ],
      "metadata": {
        "id": "-fjYkXX4FDRQ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain (llm = llm, prompt=prompt_template_for_vacation, memory=memory)\n",
        "\n",
        "country = chain.run(\"Europe\")\n",
        "\n",
        "to_markdown(country)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "fZGjHaikFSj9",
        "outputId": "fba9325f-7c99-4f3a-bfc2-a3c37a190c4b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Italy"
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "country = chain.run(\"Asia\")\n",
        "\n",
        "to_markdown(country)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "mP4CxREVF2yu",
        "outputId": "14d9c933-e673-4410-9f91-dd2263b51994"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">Japan"
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovJtl3NiLRAX",
        "outputId": "1e3bad64-cb22-4a63-9a9b-5a5e6be04433"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Europe\n",
            "AI: Italy\n",
            "Human: Europe\n",
            "AI: Italy\n",
            "Human: Asia\n",
            "AI: Japan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conversation Chain Memory**"
      ],
      "metadata": {
        "id": "x8VJ8flaGph_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "history = ConversationChain(llm=llm)\n",
        "\n",
        "print(history.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_IvtkoWG_3W",
        "outputId": "4274799b-1b82-481a-eed8-8910549fd168"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.run(\"what date is the next US presidential elections? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hfhwW6YQMKBj",
        "outputId": "5e41f712-b0db-4fb3-b900-0375a7bbde31"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The next US presidential election will be held on Tuesday, November 5, 2024.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki0PQ1gMeZy",
        "outputId": "f4df14cc-112b-4a8e-e974-9c2dd5d00eb0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: what date is the next US presidential elections? \n",
            "AI: The next US presidential election will be held on Tuesday, November 5, 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conversation Buffer Window Memory**"
      ],
      "metadata": {
        "id": "LKvcpNeFHBSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)"
      ],
      "metadata": {
        "id": "oqyxTvHyM2mW"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ConversationChain(llm=llm,memory=memory)"
      ],
      "metadata": {
        "id": "H0QV1G9cHAye"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.run(\"what date is the next US presidential elections? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oxjeGkB6N4Q7",
        "outputId": "aa0c588b-8a06-4655-a3b7-a5bb4ab3cf80"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The next US presidential election will be held on Tuesday, November 5, 2024.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.run(\"who is the richest woman in the world\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KFz2nnQ2N6Wh",
        "outputId": "8e2245bc-3bf1-4610-df6a-8a9c81ef397a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to Forbes, as of March 2023, Françoise Bettencourt Meyers is the richest woman in the world with an estimated net worth of $94.2 billion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6OK43nQOB1x",
        "outputId": "f4b99c62-b4b4-4ada-8571-f251efb03208"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: who is the richest woman in the world\n",
            "AI: According to Forbes, as of March 2023, Françoise Bettencourt Meyers is the richest woman in the world with an estimated net worth of $94.2 billion.\n"
          ]
        }
      ]
    }
  ]
}